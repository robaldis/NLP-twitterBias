{
 "cells": [
  {
   "source": [
    "# Cleaning data\n",
    "To clean the data all of the non-words need to be removed so the data can be understood better. \n",
    "\n",
    "### Imports\n",
    "* re - regular expression to remove unwanted words and characters\n",
    "* pickle - to pickle the data for later\n",
    "* pandas - to represent the data in a dataframe\n",
    "* string - help with the regular expression and removing punctuation\n",
    "* sklearn - turn into a Document term matrix\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the pickle dataframe with the raw data\n",
    "with open('twitterBias/notebooks/pickle/rawDataFrame.p', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"https\\S+\", \" \", text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round2(text):\n",
    "    EMOJI_PATTERN = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\")\n",
    "    text = re.sub(EMOJI_PATTERN,r' ', text)\n",
    "    return text\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(df.tweets.apply(round1))\n",
    "data_clean = pd.DataFrame(data_clean.tweets.apply(round2))\n",
    "\n",
    "# Save the clean corpus to a pickle file\n",
    "with open ('twitterBias/notebooks/pickle/corpus.p', 'wb') as f:\n",
    "    pickle.dump(data_clean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "yobeccz even when i think i’m eating sugar  mfp says i ate sugarthe best receiver in the nfl   kim’s convenience after a football sunday that couldn’t have gone better   jagster7985 can i chop it up with you guys i’m chomping at the bit waiting for my cs4 review code trevarnold ikepackers especially in a system like matt lafleur’s where it’s hard for a rookie to pick it up  the best draft pick on the field today might’ve even been josiah deguara  nobody called thattrevarnold ikepackers can’t look back at that now remember we picked 3 receivers in the draft two years ago 2 are still on the team the time to rate that draft is after this year  they’re not meant to be judged immediatelytrevarnold ikepackers the achilles heel aside from the poor run defense  aaron rodgers not playing like the bad man that he iseven san francisco folded because of talent deficiency at qb once mahomes started rollingtrevarnold ikepackers sf did that to min too last year  and they supposedly had a good run defenseevery opponent has to be played differently  and we had a rock solid plan at min today just go out there and execute rodgers will be the first to tell you he didn’t execute in santa clara too      stadium looks like an upside down swoosh i dig it love to go to a game or an event there once we’re allowed tolike how did they get marshawn to do this commercial when skittles aren’t involvedi love this chips commercialrobert woods cooper kupp  and now van jefferson rams doing much more than dallas’ unheralded offenseraffraff73 played 12 games new system did next to nothing his rookie year consistency these experts are acting like the cowboys have had a highoctane passing offense for yearsraffraff73 he’s fine i wanna see a full season of consistency further breakout candidate surecarrie underwood is wearing pants so moms can stop complaining about the snf intro being too sexualizedthe only proven receiver dallas has is amari cooper  and i’m sorry to say it  america he’s not dak good either\n"
    }
   ],
   "source": [
    "print(data_clean.tweets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     000  000we  003  010  02  0400  078  09  0g  0n  ...  óscar  \\\n0      0      0    0    0   0     0    0   0   0   0  ...      0   \n1      0      0    0    0   0     0    0   0   0   0  ...      0   \n2      0      0    0    0   0     0    0   0   0   0  ...      0   \n3      0      0    0    0   0     0    0   0   0   0  ...      0   \n4      0      0    0    0   0     0    0   0   0   0  ...      0   \n..   ...    ...  ...  ...  ..   ...  ...  ..  ..  ..  ...    ...   \n386    0      0    0    0   0     0    0   0   0   0  ...      0   \n387    0      0    0    0   0     0    0   0   0   0  ...      0   \n388    0      0    0    0   0     0    0   0   0   0  ...      0   \n389    0      0    0    0   0     0    0   0   0   0  ...      0   \n390    0      0    0    0   0     0    0   0   0   0  ...      0   \n\n     óscarsimongbrooks  öyster  última  þórisson  петер  термéн  საქართველო  \\\n0                    0       0       0         0      0       0           0   \n1                    0       0       0         0      0       0           0   \n2                    0       0       0         0      0       0           0   \n3                    0       0       0         0      0       0           0   \n4                    0       0       0         0      0       0           0   \n..                 ...     ...     ...       ...    ...     ...         ...   \n386                  0       0       0         0      0       0           0   \n387                  0       0       0         0      0       0           0   \n388                  0       0       0         0      0       0           0   \n389                  0       0       0         0      0       0           0   \n390                  0       0       0         0      0       0           0   \n\n     ᵃʳᵉ  ᵗʰᵉʸ  \n0      0     0  \n1      0     0  \n2      0     0  \n3      0     0  \n4      0     0  \n..   ...   ...  \n386    0     0  \n387    0     0  \n388    0     0  \n389    0     0  \n390    0     0  \n\n[391 rows x 15150 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000</th>\n      <th>000we</th>\n      <th>003</th>\n      <th>010</th>\n      <th>02</th>\n      <th>0400</th>\n      <th>078</th>\n      <th>09</th>\n      <th>0g</th>\n      <th>0n</th>\n      <th>...</th>\n      <th>óscar</th>\n      <th>óscarsimongbrooks</th>\n      <th>öyster</th>\n      <th>última</th>\n      <th>þórisson</th>\n      <th>петер</th>\n      <th>термéн</th>\n      <th>საქართველო</th>\n      <th>ᵃʳᵉ</th>\n      <th>ᵗʰᵉʸ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>391 rows × 15150 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean.tweets)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data_clean.index\n",
    "#data_dtm=data_dtm.transpose()\n",
    "\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the data for later\n",
    "data_dtm.to_pickle(\"twitterBias/notebooks/pickle/dtm.pkl\")"
   ]
  },
  {
   "source": [
    "# Final results\n",
    "The data has been converted to a corpus and a document term matrix, this should be all that's needed to analyse the data to find anything meaning full. \n",
    "\n",
    "There might have to be more data cleaning steps that have to be done after analysing the data if there are any anomilies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}